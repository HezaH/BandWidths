%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{float}
\usepackage{graphicx,url}  
\usepackage[utf8]{inputenc}  

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{indentfirst}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{fancybox}

\setlength{\parskip}{0pt}
\setlength{\parindent}{1.25cm}

\sloppy

\title{Otimização de Largura de Banda em Grafos \\ Utilizando Aprendizado por Reforço Profundo}

\author{Hélio H. Souza\inst{1}}
\affil{Orientador: Diego N. Brandão\inst{2}}

\address{Centro Federal de Educação Tecnológica Celso Suckow da Fonseca (CEFET/RJ)\\
  Av. Maracanã, 229 - Maracanã – Rio de Janeiro/RJ - CEP: 20271-110
\nextinstitute
  Programa de Pós-graduação em Ciência da Computação (PPCIC)\\
  \email{helio.souza@aluno.cefet-rj.br}
  \email{diego.brandao@cefet-rj.br}
}

\begin{document} 

\maketitle

\begin{abstract}
This work presents a comprehensive methodology for graph bandwidth optimization 
by integrating Deep Q-Learning with centrality-based heuristics. The approach combines 
reinforcement learning with network topology analysis to solve the NP-complete bandwidth 
minimization problem. We implement a multi-layer architecture consisting of an intelligent 
agent, an optimization environment, and a graph representation layer. Seven complementary 
centrality measures (Degree, Closeness, Betweenness, Eigenvector, Katz, PageRank, and 
Harmonic) guide the construction of labeling solutions through a hybrid greedy algorithm. 
Experimental results demonstrate the effectiveness of the proposed adaptive strategy in 
reducing bandwidth while maintaining computational efficiency across diverse sparse graph 
instances.
\end{abstract}

\begin{resumo} 
Este trabalho apresenta uma metodologia abrangente para otimização de largura de banda 
em grafos integrando Aprendizado por Reforço Profundo (\textit{Deep Q-Learning}) com heurísticas 
baseadas em centralidade. A abordagem combina aprendizado de máquina com análise de topologia 
de rede para resolver o problema NP-completo de minimização de largura de banda. 
Implementamos uma arquitetura de múltiplas camadas consistindo de um agente, 
um ambiente de otimização e uma camada de representação de grafo. Sete medidas 
complementares de centralidade (Grau, Proximidade, Intermediação, Autovetor, Katz, PageRank 
e Harmônica) guiam a construção de soluções de rótulação através de um algoritmo guloso 
híbrido. Os resultados experimentais demonstram a eficácia da estratégia adaptativa proposta 
na redução de largura de banda mantendo eficiência computacional em diversas instâncias de 
grafos esparsos.
\end{resumo}

\section{Introdução}

A redução e reordenação de matrizes é etapa central em álgebra linear numérica, otimização, análise de grafos e simulação computacional. O objetivo é transformar estruturas matriciais complexas em representações mais compactas e eficientes; porém, muitos problemas associados à reorganização, eliminação ou compressão pertencem à classe NP-difícil: à medida que crescem o número de vértices ou conexões, o custo de processamento aumenta rapidamente e não se conhecem algoritmos exatos polinomiais.

Nesse cenário, heurísticas surgem como alternativas práticas. São estratégias que não garantem ótima global, mas entregam soluções de boa qualidade com custo computacional reduzido. São comuns aplicações como ordenação de linhas/colunas para minimizar perfil ou largura de banda de matrizes esparsas, identificação de blocos estruturais e escolha de pivôs em fatorações. Tais técnicas exploram propriedades estruturais (conectividade, grau, excentricidade) e variam de buscas locais e algoritmos gulosos a métodos evolutivos, algoritmos genéticos e aprendizado por reforço \cite{carneiro2024sbpo}. Integradas ao pré-processamento, melhoram substancialmente o desempenho de métodos diretos e iterativos.

Este trabalho descreve uma metodologia acadêmica que combina teoria dos grafos, otimização combinatória e inteligência artificial para atacar a minimização da largura de banda, problema clássico e NP-difícil com aplicações em processamento numérico, engenharia estrutural e análise de redes complexas. Propomos um sistema inteligente que integra Aprendizado por Reforço Profundo (\textit{Deep Q-Learning} - DQN) a heurísticas baseadas em medidas de centralidade de rede, permitindo selecionar dinamicamente a estratégia mais promissora. A abordagem usa centralidades complementares e um agente DQN para orquestrar, em tempo de execução, múltiplas heurísticas construtivas, equilibrando rigor matemático e viabilidade computacional.



\section{Definição do Problema}


\subsection{Matriz esparsa} \label{matriz_esparsa}

Uma \emph{matriz esparsa} é uma matriz que possui uma grande proporção de entradas iguais a zero. Ela surge com frequência ao discretizar problemas contínuos (por exemplo, equações diferenciais parciais), ao representar grafos por matrizes de adjacência, ou ao lidar com conjuntos de dados com muitas ausências. Para economizar memória e tempo de processamento, costuma‑se armazenar apenas as entradas não nulas e suas posições. Como referência, 
apresenta-se o exemplo a seguir com apenas cinco entradas não nulas, o que justifica o uso de estruturas compactas para armazenamento.

\medskip

\textbf{Exemplo:} uma matriz \(4\times4\) esparsa típica

\[
A=\begin{bmatrix}
10 & 0 & 0 & 0\\
0 & 5 & 0 & 2\\
0 & 0 & 0 & 0\\
0 & 2 & 0 & 7
\end{bmatrix}
\]


\subsection{Conceituação de Largura de Banda} \label{largura_banda}

A largura de banda (\textit{bandwidth}) de um grafo é uma métrica que representa a diferença máxima de distância entre rótulos de vértices adjacentes. Formalmente, para um grafo $G = (V, E)$ com uma rotulação (\textit{labeling}) $f: V \rightarrow \{1, 2, \ldots, n\}$, a largura de banda é definida como:

\begin{equation}
BW(G, f) = \max_{(u,v) \in E} |f(u) - f(v)|
\end{equation}

A importância prática da minimização da largura de banda manifesta-se em diversos domínios. Bem como a melhoria no armazenamento e processamento eficiente de matrizes esparsas [\ref{matriz_esparsa}]. Outro ponto, é a redução do escopo de busca em algoritmos de fatoração, otimizando o uso de cache em sistemas computacionais, que favorecem sua utilização. Além disso, a minimização da largura de banda é crucial no processamento de sistemas de equações lineares de grande escala, na análise de redes complexas e sistemas estruturados.

\subsection{Complexidade Computacional}

O problema de minimização de largura de banda é classificado como NP-completo, o que implica que não existe um algoritmo conhecido que possa resolvê-lo em tempo polinomial para todas as instâncias. Consequentemente, para grafos de grande escala, torna-se inviável buscar soluções ótimas através de métodos exatos devido seu tempo de execução exponencial. Por outro lado, abordagens exatas são viáveis para utilizações de instâncias pequenas ($n < 100$). Assim, a utilização de heurísticas e metaheurísticas torna-se essencial para encontrar soluções aproximadas em um tempo computacional razoável.

\section{Estrutura Geral do Algoritmo}

\subsection{Arquitetura de Três Camadas}

O sistema proposto é estruturado em três camadas integradas e hierárquicas. A primeira camada consiste no agente de aprendizado, responsável por selecionar estratégias de otimização com base no estado atual do ambiente. Nessa etapa, implementamos um agente Deep Q-Network (DQN) que aprende a escolher entre diferentes heurísticas de centralidade e constrói soluções de rótulação de forma adaptativa atribuindo recompensas ou penalidades conforme o desempenho obtido pelo ambiente.

A segunda camada é o ambiente de otimização, que implementa as heurísticas de centralidade e gerencia a interação com o agente. Essa camada executa as heurísticas selecionadas, avalia as soluções geradas e calcula métricas de desempenho, como a largura de banda resultante. Ela também atualiza o estado do ambiente com base nas ações do agente e fornece um retorno quantitativo através da função de recompensa.

A terceira camada é a representação do grafo, que fornece a estrutura de dados necessária para armazenar e manipular o grafo em questão. A cada iteração do agente, essa camada atualiza a representação do grafo conforme as soluções geradas pelas heurísticas, garantindo que o ambiente de otimização tenha acesso às informações mais recentes para avaliação e tomada de decisão, bem como memorização das instâncias carregadas em cada tentativa.

\section{Técnica Principal: Aprendizado por Reforço Profundo (DQN)}

\subsection{Fundamentos Teóricos}

O Aprendizado por Reforço (Reinforcement Learning - RL) é um paradigma onde um agente aprende através da interação com o ambiente, recebendo recompensas (\textit{rewards}) por ações bem-sucedidas. No contexto deste projeto, implementamos \textit{Deep Q-Learning}, que combinama \textit{Q-Learning} tradicional com redes neurais profundas para aproximar a função de valor de ação $Q(s,a)$ [\ref{bellman_eq}]. Essa técnica é particularmente eficaz em ambientes com espaços de estados e ações grandes ou contínuos, onde tabelas tradicionais seriam impraticáveis. Esta abordagem híbrida permite que o agente generalize sobre um espaço de estados contínuo, algo de bastante dificuldade em \textit{Q-Learning} tabular tradicional.

\subsection{Equação de Bellman Aplicada}

A atualização de valores Q, que mede o quão boa é determinada ação, é realizada através da equação de Bellman:

\begin{equation}
Q(s,a) \leftarrow Q(s,a) + \alpha[r + \gamma \max_{a'} Q(s',a') - Q(s,a)]
\end{equation} \label{bellman_eq}

Onde $Q(s,a)$ representa o valor esperado da ação $a$ no estado $s$, $r$ é a recompensa imediata recebida após executar a ação, $s'$ é o estado resultante, $\alpha$ é a taxa de aprendizado e $\gamma$ é o fator de desconto que pondera a importância das recompensas futuras.

\subsection{Política Epsilon-Greedy}

O agente implementa uma estratégia de \textit{exploration-exploitation} balanceada, visando a busca local ou global.

\begin{equation}
\text{ação} = \begin{cases} 
\text{aleatória} & \text{com probabilidade } \epsilon \\
\argmax_a Q(s,a) & \text{com probabilidade } 1-\epsilon
\end{cases}
\end{equation}

O decaimento de epsilon ao longo do tempo é configurado seguindo um valor inicial ($\epsilon = 1.0$) que diminui gradualmente até um valor mínimo ($\epsilon_{\min} = 0.01$). A taxa de decaimento é definida como $\epsilon_{\text{decay}} = 0.995$, o que significa que após cada passo, o valor de epsilon é atualizado multiplicando-o por 0.995.

Este mecanismo permite que o agente explore o espaço de ações ampla e aleatoriamente no início do treinamento, convergindo gradualmente para uma estratégia mais determinística e otimizada conforme acumula experiência.

\subsection{Função de Recompensa - \textit{r}}

A função de recompensa é estruturada para incentivar melhorias consistentes e inovação das soluções análisadas. A recompensa é calculada com base na comparação entre a largura de banda da solução atual ($BW_{\text{nova}}$), a melhor largura de banda histórica ($BW_{\text{melhor}}$) e a largura de banda da iteração anterior ($BW_{\text{anterior}}$):

\begin{equation}
r = \begin{cases}
Recompensa Máxima & \text{se } BW_{\text{nova}} \leq BW_{\text{melhor}}\\
Recompensa Intermediária & \text{se } BW_{\text{nova}} \leq BW_{\text{anterior}} \text{ (melhoria local)} \\
Penalidade Suave & \text{caso contrário (piora ou estagnação)}
\end{cases}
\end{equation}

Na qual as recompensa máxima dita a melhorias globais com inovação (descoberta de nova solução ótima), enquanto a recompensa intermediária reconhece avanços incrementais. A penalidade suave desestimula escolhas que não contribuem para o progresso, mas sem eliminar completamente a ação, permitindo que o agente explore alternativas.


\section{Heurísticas de Centralidade}

\subsection{Conceito de Centralidade em Redes}

Centralidade é uma métrica que quantifica a importância relativa de um nó em uma rede. A hipótese fundamental do projeto é que ordenar os vértices conforme sua importância estrutural (centralidade) resulta em soluções de largura de banda próximas ao ótimo.

Esta suposição baseia-se na observação empírica de que nós centrais frequentemente possuem propriedades que facilitam sua rótulação de forma, o que é possível utilizar como referência para reduzir a largura de banda global.

\subsection{Medidas de Centralidade Utilizadas}

Dado uma possibilidade de centralidade utilizada na formulação, a diversidade dessas medidas permite que o agente experimente múltiplas estratégias de ordenação, aprendendo qual é mais eficaz para cada classe de grafo. O sistema utiliza sete medidas complementares de centralidade, cada uma capturando diferentes aspectos da importância estrutural:

\subsubsection{Degree Centrality (Grau)}

\begin{equation}
C_D(v) = \frac{\deg(v)}{n-1}
\end{equation}

Mede o número de conexões diretas. Vértices altamente conectados recebem maior prioridade. É uma medida local que não leva em conta a topologia global.

\subsubsection{Closeness Centrality (Proximidade)}

\begin{equation}
C_C(v) = \frac{n-1}{\sum_{u \neq v} d(v,u)}
\end{equation}

Identifica vértices que, em média, estão próximos de todos os outros. Reflete a capacidade de propagação de informações e é uma medida global baseada em distâncias.

\subsubsection{Betweenness Centrality (Intermediação)}

\begin{equation}
C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}
\end{equation}

Mede quantos caminhos mais curtos passam por um vértice. Identifica ``pontes'' estruturais na rede que são essenciais para conectividade.

\subsubsection{Eigenvector Centrality (Autovetor)}

\begin{equation}
C_E(v) = \frac{1}{\lambda} \sum_{u \in N(v)} C_E(u)
\end{equation}

Considera a importância dos vizinhos. Nós conectados a nós importantes são considerados mais importantes. Baseada em propriedades espectrais.

\subsubsection{Katz Centrality}

\begin{equation}
C_K(v) = \alpha \sum_{u} A_{vu} C_K(u) + \beta
\end{equation}

Generalização que considera caminhos de todas as comprimentos, com decaimento exponencial.

\subsubsection{PageRank}

O \emph{PageRank} é uma métrica de centralidade em grafos que avalia a importância de um vértice $v$ pela soma das contribuições dos seus vizinhos. Cada vizinho $u$ transfere parte de sua relevância proporcional ao seu grau de saída $\deg(u)$. O fator de amortecimento $d$ controla a probabilidade de seguir uma aresta ou reiniciar em um vértice aleatório, garantindo estabilidade.

\begin{equation}
PR(v) = \frac{1-d}{n} + d \sum_{u \in N(v)} \frac{PR(u)}{\deg(u)}
\end{equation}

\subsubsection{Harmonic Centrality}

\begin{equation}
C_H(v) = \sum_{u \neq v} \frac{1}{d(v,u)}
\end{equation}

Versão modificada de closeness que não sofre com grafos desconectados, permitindo aplicação em redes com múltiplas componentes conectadas.


\section{Propriedades Topológicas Calculadas} \label{propriedades_topologicas}

O sistema não apenas otimiza \textit{bandwidth}, mas também coleta dados abrangentes sobre características estruturais dos grafos analisados, dos quais fazem parte das análises na seção de Resultados [\ref{resultados}]. Essas propriedades fornecem clarezas sobre a complexidade e a dinâmica das redes, auxiliando na compreensão do impacto da topologia na eficácia das heurísticas aplicadas.

\subsection{Conectividade de Nó}

\begin{equation}
NC(G) = \min k \text{ | remoção de } k \text{ nós desconecta } G
\end{equation}

Mede a robustez mínima do grafo contra remoção de nós.

\subsection{Conectividade de Aresta}

\begin{equation}
EC(G) = \min k \text{ | remoção de } k \text{ arestas desconecta } G
\end{equation}

Medida dual que avalia robustez contra remoção de arestas.

\subsection{Conectividade Algébrica}

\begin{equation}
\mu(G) = \lambda_2(L_G)
\end{equation}

Segundo autovalor da matriz Laplaciana - mede coesão global da rede e velocidade de convergência de processos dinâmicos.

\subsection{Densidade do Grafo}

\begin{equation}
\rho(G) = \frac{2m}{n(n-1)}
\end{equation}

Razão entre arestas existentes e máximo possível. Varia de 0 (desconectado) a 1 (completo).

\subsection{Distância Média de Caminho Mais Curto}

\begin{equation}
ASPL = \frac{1}{\binom{n}{2}} \sum_{u < v} d(u,v)
\end{equation}

Eficiência média de propagação na rede. Importante para redes de comunicação.

\subsection{Diâmetro}

\begin{equation}
D(G) = \max_{u,v} d(u,v)
\end{equation}

Maior distância entre qualquer par de nós. Caracteriza o alcance máximo de propagação.

\subsection{Componentes Conectadas}

\begin{equation}
cc(G) = \text{número de subgrafos conexos}
\end{equation}

Identifica se o grafo é conexo (cc = 1) ou possui múltiplas componentes isoladas.

\section{Heurística Construtiva: LCR (Least Cost Respects)}

\subsection{Princípio Base}

A heurística construtiva implementa uma estratégia gulosa ponderada que constrói soluções iterativamente:

\begin{equation}
\text{Score}(v) = (1-\alpha) \times C(v) + \alpha \times \text{rand}()
\end{equation}

Onde cada vértice $v$ é avaliado com base em sua medida de centralidade $C(v)$ e um componente aleatório. O parâmetro $\alpha$ controla o equilíbrio entre a influência da centralidade e a aleatoriedade na seleção dos vértices.

\section{Funcionamento}

\subsection{Processo de \textStepping}

A cada iteração do treinamento, após a obtenção do grafo em análise e as propriedades topológicas calculadas [\ref{propriedades_topologicas}], o seguinte processo é executado:

\begin{table}[H]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Etapa} & \textbf{Descrição} \\
\hline
1 & Agente seleciona centralidade via política $\epsilon$-greedy. \\
\hline
2 & Ambiente executa 5 tentativas da heurística com essa centralidade. \\
\hline
3 & Cada tentativa gera 3 soluções. \\
\hline
4 & Total de 15 soluções avaliadas por iteração. \\
\hline
5 & Melhor solução desta rodada é comparada com histórico global. \\
\hline
6 & Estado e recompensa são retornados ao agente. \\
\hline
7 & Agente atualiza rede neural com nova experiência \textit{(backward pass)}. \\
\hline
8 & Epsilon é decrementado (exploração reduzida para próxima iteração). \\
\hline
\end{tabular}
\caption{Fases do processo de stepping do ambiente}
\end{table}

\section{Resultados}

Nessa seção, apresentamos uma análise detalhada dos resultados obtidos através da aplicação do sistema proposto em diversas instâncias de grafos esparsos. A avaliação foca na eficácia da combinação de Aprendizado por Reforço Profundo com heurísticas de centralidade na minimização da largura de banda. Também foi levantada a influência das propriedades topológicas dos grafos na performance das soluções geradas, em função de representações visuais.

\subsection{Interpretação das Métricas por Instância.}

Para quantificar a melhoria obtida por cada centralidade, adotou‑se a taxa de melhoria relativa entre a largura de banda inicial e a obtida após aplicação da centralidade. A métrica utilizada é dado pela equação \ref{eq:decay},  onde valores maiores indicam maior redução (melhoria).

\begin{equation}
\label{eq:decay}
\mathrm{Decay} \;=\; \frac{\text{Initial Bandwidth} - \text{BandCentrality}}{\text{Initial Bandwidth}} \times 100\%
\end{equation}

A Tabela 1 apresenta um resumo dos resultados obtidos para diversas instâncias de grafos esparsos, incluindo a largura de banda inicial, a largura de banda após aplicação da centralidade selecionada, o tipo de centralidade utilizada, o número de arestas e nós do grafo, bem como a taxa de decaimento calculada.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Initial Band} & \textbf{BandCentrality} & \textbf{Centrality} & \textbf{Instance} & \textbf{Edges} & \textbf{Nodes} & \textbf{Decay \%} \\
\hline
1549 & 573 & Eigenvector & bp\_0 & 3275 & 822 & 63.01 \\
1643 & 639 & Eigenvector & bp\_1000 & 4657 & 822 & 61.11 \\
1643 & 641 & PageRank & bp\_1200 & 4720 & 822 & 60.99 \\
1643 & 643 & Betweenness & bp\_1400 & 4785 & 822 & 60.86 \\
1643 & 646 & Closeness & bp\_1600 & 4835 & 822 & 60.68 \\
1633 & 596 & Betweenness & bp\_200 & 3800 & 822 & 63.50 \\
1627 & 628 & Closeness & bp\_400 & 4026 & 822 & 61.40 \\
1627 & 624 & Harmonic Centrality & bp\_600 & 4170 & 822 & 61.65 \\
1643 & 631 & PageRank & bp\_800 & 4530 & 822 & 61.59 \\
1285 & 523 & PageRank & shl\_0 & 1682 & 663 & 59.30 \\
1953 & 51 & Degree & lshp1009 & 2928 & 1009 & 97.39 \\
2457 & 59 & Degree & lshp1270 & 3699 & 1270 & 97.60 \\
3019 & 68 & Degree & lshp1561 & 4560 & 1561 & 97.75 \\
3641 & 74 & Degree & lshp1882 & 5511 & 1882 & 97.97 \\
4333 & 80 & Degree & lshp2233 & 6552 & 2233 & 98.15 \\
5085 & 89 & Degree & lshp2614 & 7683 & 2614 & 98.25 \\
5897 & 95 & Degree & lshp3025 & 8904 & 3025 & 98.39 \\
6769 & 104 & Degree & lshp3466 & 10215 & 3466 & 98.46 \\
511 & 26 & Degree & lshp\_265 & 744 & 265 & 94.91 \\
783 & 33 & Degree & lshp\_406 & 1155 & 406 & 95.79 \\
71 & 29 & Harmonic Centrality & bcsstk01 & 176 & 48 & 59.15 \\
131 & 65 & Katz Centrality & bcsstk02 & 2145 & 66 & 50.38 \\
109 & 58 & Closeness & bcsstk04 & 1758 & 132 & 46.79 \\
55 & 29 & Katz Centrality & bcsstk05 & 1135 & 153 & 47.27 \\
147 & 78 & Eigenvector & bcsstk06 & 3720 & 420 & 46.94 \\
147 & 78 & Closeness & bcsstk07 & 3720 & 420 & 46.94 \\
2509 & 561 & Degree & bcsstk13 & 40940 & 2003 & 77.64 \\
1185 & 205 & Degree & orsirr\_1 & 5828 & 1030 & 82.70 \\
1185 & 199 & Katz Centrality & orsirr\_2 & 5084 & 886 & 83.21 \\
185 & 97 & Degree & bfwa398 & 3280 & 398 & 47.57 \\
77 & 23 & Degree & bfwa62 & 388 & 62 & 70.13 \\
265 & 145 & Harmonic Centrality & bfwa782 & 6732 & 782 & 45.28 \\
2133 & 117 & Degree & dw1024 & 8066 & 2048 & 94.51 \\
537 & 66 & Degree & dw256A & 1968 & 512 & 87.71 \\
555 & 57 & PageRank & dw256B & 1988 & 512 & 89.73 \\
9241 & 244 & Harmonic Centrality & dw4096 & 33554 & 8192 & 97.36 \\
\hline
\end{tabular}
\caption{Comparação entre banda inicial, banda após aplicação de centralidade, instância, número de arestas, número de nós e taxa de decaimento}
\end{table}

Os resultados revelam três regimes estruturais. Nas instâncias da família \texttt{bp\_}, a largura de banda cai cerca de 60\%, mas o agente alterna entre métricas globais (Betweenness, Closeness, Harmonic) e espectrais (Eigenvector, PageRank) conforme o tamanho do grafo cresce. Isso confirma que grafos com maior diâmetro exigem medidas capazes de capturar dependências de longo alcance para organizar vértices periféricos antes dos centrais. É possivel observar na figura abaixo \ref{fig:bp1600}, a frequência com que o agente DQN selecionou cada centralidade ao longo do treinamento na instância \texttt{bp\_1600}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/plot_frequency_bp_1600.png}
    \caption{Frequência de centralidade da instância \texttt{bp\_1600}.} \label{fig:bp1600}
\end{figure}

Nas instâncias \texttt{lshp}, a centralidade de Grau domina e entrega reduções superiores a 98\%. Esses grafos apresentam hubs pronunciados e conectividade assimétrica (densidade local alta, mas componentes bem definidas), de modo que ordenar vértices apenas pelo número de vizinhos já posiciona os nós críticos nas extremidades da matriz, minimizando o espalhamento das arestas. Na figura abaixo ~\ref{fig:lshp1882}, observa-se a frequência com que o agente DQN selecionou cada centralidade ao longo do treinamento na instância \texttt{lshp1882}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/plot_frequency_lshp1882.png}
    \caption{Frequência de centralidade da instância \texttt{lshp1882}.} \label{fig:lshp1882}
\end{figure}

Por fim, os conjuntos \texttt{bcsstk}, \texttt{dw} e \texttt{bfwa} ilustram um cenário híbrido: grafos estruturais com múltiplas componentes favorecem Katz e Harmonic, que tratam desconexões sem penalizar distâncias infinitas, enquanto malhas regulares (\texttt{dw256}, \texttt{dw4096}) alternam entre Degree e PageRank para equilibrar simetria e presença de vértices articuladores. Em todos os casos, o agente DQN ajusta dinamicamente a centralidade escolhida, indicando que a camada de aprendizado realmente captura sinais topológicos produzidos na Seção ~\ref{propriedades_topologicas} e os transforma em ganhos concretos de largura de banda.

\subsection{Distribuições de Largura de Banda por Centralidade} \label{distribuicoes_largura_banda}
O gráfico principal é um \emph{violin plot} que combina densidade, caixa e pontos individuais; a legenda é atualizada para exibir, de forma explícita, a sigla seguida do nome completo da centralidade. A forma do violino mostra a densidade dos valores de \textit{bandwidth} por centralidade, permitindo identificar concentrações e lacunas na distribuição. A caixa e a mediana incorporadas no violino facilitam a comparação de tendência central e dispersão entre centralidades, apontando quais métodos tendem a produzir valores mais baixos de largura de banda. A plotagem de todos os pontos evidencia outliers e variabilidade amostral, o que é útil para distinguir centralidades robustas de outras cujo desempenho depende fortemente da amostra específica.

Reportam‑se estatísticas resumo por centralidade — mediana, média, desvio padrão e intervalo interquartil — e devem ser realizadas comparações pareadas entre centralidades para instâncias específicas a fim de destacar diferenças significativas entre seus desempenhos.  A seguir apresentam‑se duas figuras exemplares que ilustram padrões distintos: a instância \texttt{dw4096} (com forte decaimento e comportamento dominado por certas centralidades) e a instância \texttt{bcsstk07} (com distribuição mais concentrada e menor variabilidade entre métodos). Essas imagens servem tanto para evidenciar diferenças de escala entre instâncias quanto para mostrar como a forma dos violinos e a presença de outliers orientam a interpretação quantitativa. Observa‑se forte redução média e alta variabilidade entre centralidades; violinos estreitos indicam resultados consistentes, enquanto violinos largos e pontos dispersos revelam maior sensibilidade à amostra. Também é observado que a mediana das centralidades nas quais são mais próxima os violinos são mais compactos, sugerindo desempenho mais homogêneo entre heurísticas.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/grafico_bandwidth_dw4096.png}
    \caption{Distribuição de \textit{bandwidth} por centralidade para a instância \texttt{dw4096}. }
    \label{fig:dw4096}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/grafico_bandwidth_bcsstk07.png}
    \caption{Distribuição de \textit{bandwidth} por centralidade para a instância \texttt{bcsstk07}.}
    \label{fig:bcsstk07}
\end{figure}

A importância dessas representações gráficas reside em três pontos principais. Primeiro, os violin plots permitem visualizar simultaneamente tendência central e densidade, o que facilita a identificação da centralidade que, em média, reduz mais a largura de banda. Segundo, a sobreposição de pontos individuais evidencia outliers e casos extremos que podem distorcer médias; por isso, a mediana e o IQR são métricas complementares essenciais. Terceiro, ao comparar figuras de diferentes instâncias (por exemplo, Figura~\ref{fig:dw4096} versus Figura~\ref{fig:bcsstk07}) é possível relacionar padrões de melhoria com propriedades topológicas do grafo (número de nós, presença de hubs, densidade local), orientando hipóteses sobre por que certa centralidade funciona melhor em determinados cenários.

\section{Conclusão}

A metodologia apresentada integra de forma inovadora técnicas de aprendizado de máquina com heurísticas topológicas para abordar o problema clássico de minimização de largura de banda. A utilização de \textit{Deep Q-Learning} permite que o sistema aprenda dinamicamente qual estratégia de centralidade é mais eficaz para cada tipo de grafo, superando significativamente abordagens estáticas tradicionais.

Os componentes principais trabalham em harmonia:
\begin{itemize}
    \item Agente neural adaptativo que melhora continuamente sua política de seleção
    \item Sete medidas de centralidade complementares oferecendo perspectivas diversas
    \item Heurística construtiva híbrida balanceando determinismo com aleatoriedade
    \item Ambiente de feedback dinâmico que molda o aprendizado do agente
\end{itemize}

Este trabalho demonstra o potencial significativo de combinar inteligência artificial clássica com otimização estruturada em domínios combinatórios, abrindo caminho para futuras pesquisas em metaheurísticas inteligentes e aprendizado adaptativo em problemas complexos.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
